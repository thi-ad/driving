<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Primary Meta Tags -->
  <!-- TODO: Replace with your paper title and author names -->
  <meta name="title" content="DrivIng">
  <!-- TODO: Write a compelling 150-160 character description of your research -->
  <meta name="description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Add 5-10 relevant keywords for your research area -->
  <meta name="keywords" content="KEYWORD1, KEYWORD2, KEYWORD3, machine learning, computer vision, AI">
  <!-- TODO: List all authors -->
  <meta name="author" content="FIRST_AUTHOR_NAME, SECOND_AUTHOR_NAME">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">

  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <!-- TODO: Replace with your institution or lab name -->
  <meta property="og:site_name" content="INSTITUTION_OR_LAB_NAME">
  <!-- TODO: Same as paper title above -->
  <meta property="og:title" content="PAPER_TITLE">
  <!-- TODO: Same as description above -->
  <meta property="og:description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Replace with your actual website URL -->
  <meta property="og:url" content="https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE">
  <!-- TODO: Create a 1200x630px preview image and update path -->
  <meta property="og:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="PAPER_TITLE - Research Preview">
  <meta property="article:published_time" content="2024-01-01T00:00:00.000Z">
  <meta property="article:author" content="FIRST_AUTHOR_NAME">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="KEYWORD1">
  <meta property="article:tag" content="KEYWORD2">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <!-- TODO: Replace with your lab/institution Twitter handle -->
  <meta name="twitter:site" content="@YOUR_TWITTER_HANDLE">
  <!-- TODO: Replace with first author's Twitter handle -->
  <meta name="twitter:creator" content="@AUTHOR_TWITTER_HANDLE">
  <!-- TODO: Same as paper title above -->
  <meta name="twitter:title" content="PAPER_TITLE">
  <!-- TODO: Same as description above -->
  <meta name="twitter:description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Same as social preview image above -->
  <meta name="twitter:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta name="twitter:image:alt" content="PAPER_TITLE - Research Preview">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="PAPER_TITLE">
  <meta name="citation_author" content="FIRST_AUTHOR_LAST, FIRST_AUTHOR_FIRST">
  <meta name="citation_author" content="SECOND_AUTHOR_LAST, SECOND_AUTHOR_FIRST">
  <meta name="citation_publication_date" content="2024">
  <meta name="citation_conference_title" content="CONFERENCE_NAME">
  <meta name="citation_pdf_url" content="https://YOUR_DOMAIN.com/static/pdfs/paper.pdf">

  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">

  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <!-- TODO: Replace with your paper title and authors -->
  <title>DrivIng</title>

  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/thi_logo.png">
  <link rel="apple-touch-icon" href="static/images/thi_logo.png">

  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style"
    onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style"
    onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style"
    onload="this.onload=null;this.rel='stylesheet'">

  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>

  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">

  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>

  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "PAPER_TITLE",
    "description": "BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS",
    "author": [
      {
        "@type": "Person",
        "name": "FIRST_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      },
      {
        "@type": "Person",
        "name": "SECOND_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      }
    ],
    "datePublished": "2024-01-01",
    "publisher": {
      "@type": "Organization",
      "name": "CONFERENCE_OR_JOURNAL_NAME"
    },
    "url": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE",
    "image": "https://YOUR_DOMAIN.com/static/images/social_preview.png",
    "keywords": ["KEYWORD1", "KEYWORD2", "KEYWORD3", "machine learning", "computer vision"],
    "abstract": "FULL_ABSTRACT_TEXT_HERE",
    "citation": "BIBTEX_CITATION_HERE",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "RESEARCH_AREA_1"
      },
      {
        "@type": "Thing", 
        "name": "RESEARCH_AREA_2"
      }
    ]
  }
  </script>

  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "INSTITUTION_OR_LAB_NAME",
    "url": "https://YOUR_INSTITUTION_WEBSITE.com",
    "logo": "https://YOUR_DOMAIN.com/static/images/favicon.ico",
    "sameAs": [
      "https://twitter.com/YOUR_TWITTER_HANDLE",
      "https://github.com/YOUR_GITHUB_USERNAME"
    ]
  }
  </script>
</head>

<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <main id="main-content">
    <section class="hero">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <!-- TODO: Replace with your paper title -->
              <h1 class="title is-1 publication-title">DrivIng: A Large-Scale Multimodal Driving Dataset with Full
                Digital Twin Integration</h1>

              <div class="is-size-5 publication-authors" style="line-height: 1.6; text-align: center;">
                <span class="author-block">
                  <a href="#" target="_blank">
                    Dominik RÃ–ÃŸle</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a href="#" target="_blank">Xujun Xie</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a href="#" target="_blank">Adithya Mohan</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a href="#" target="_blank">Venkatesh Thirugnana Sambandham</a><sup>1</sup>,</span>
                <br>
                <span class="author-block">
                  <a href="#" target="_blank">Daniel Cremers</a><sup>2</sup>,
                </span>

                <span class="author-block">
                  <a href="#" target="_blank">Torsten SchÃ¶n</a><sup>1</sup></span>
              </div>


              <div class="is-size-5 publication-authors">
                <!-- TODO: Replace with your institution and conference/journal info -->
                <span class="author-block"><br>IEEE IV 2026</span>
                <!-- TODO: Remove this line if no equal contribution -->
                <!-- Equal contribution and affiliations -->
                <!-- <span class="eql-cntrb"
                  style="display:block; font-size:1.05rem; font-weight:600; color:#000000; margin-top:0.3rem;">
                  <sup>*</sup>Equal contribution. Authors listed in alphabetical order.
                </span> -->

                <span class="eql-cntrb"
                  style="display:block; font-size:1.05rem; font-weight:600; color:#000000; margin-top:0.3rem;">
                  <sup>1</sup>Technische Hochschule Ingolstadt
                </span>

                <span class="eql-cntrb"
                  style="display:block; font-size:1.05rem; font-weight:600; color:#000000; margin-top:0.2rem;">
                  <sup>2</sup>Technical University of Munich
                </span>


              </div>

              <!-- ========================= -->
              <!-- Partner and Institute Logos -->
              <!-- ========================= -->
              <section class="section" style="background-color: white;">
                <div class="container has-text-centered">
                  <h2 class="title is-4">In Collaboration With</h2>
                  <div class="columns is-centered is-multiline is-vcentered" style="margin-top: 1.5rem;">

                    <!-- AIMotion Bavaria (slightly larger) -->
                    <div class="column is-narrow" style="display: flex; justify-content: center; align-items: center;">
                      <figure class="image"
                        style="width: 170px; height: 110px; display: flex; align-items: center; justify-content: center;">
                        <img src="static/images/aimotion.png" alt="AI-Motion Bavaria"
                          style="max-height:95px; max-width:150px; object-fit:contain;">
                      </figure>
                    </div>

                    <!-- CVIMS -->
                    <div class="column is-narrow" style="display: flex; justify-content: center; align-items: center;">
                      <figure class="image"
                        style="width: 150px; height: 100px; display: flex; align-items: center; justify-content: center;">
                        <img src="static/images/cvims_logo.png" alt="CVIMS Research Group"
                          style="max-height:80px; max-width:130px; object-fit:contain;">
                      </figure>
                    </div>

                    <!-- THI -->
                    <div class="column is-narrow" style="display: flex; justify-content: center; align-items: center;">
                      <figure class="image"
                        style="width: 150px; height: 100px; display: flex; align-items: center; justify-content: center;">
                        <img src="static/images/thi_logo.png" alt="Technische Hochschule Ingolstadt"
                          style="max-height:80px; max-width:130px; object-fit:contain;">
                      </figure>
                    </div>

                    <!-- TUM -->
                    <div class="column is-narrow" style="display: flex; justify-content: center; align-items: center;">
                      <figure class="image"
                        style="width: 150px; height: 100px; display: flex; align-items: center; justify-content: center;">
                        <img src="static/images/tum.png" alt="Technical University of Munich"
                          style="max-height:80px; max-width:130px; object-fit:contain;">
                      </figure>
                    </div>

                  </div>
                </div>
              </section>


              <div class="column has-text-centered">
                <div class="publication-links">
                  <!-- TODO: Update with your arXiv paper ID -->
                  <!-- <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span> -->

                  <!-- TODO: Add your supplementary material PDF or remove this section -->
                  <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- TODO: Replace with your GitHub repository URL -->
                  <span class="link-block">
                    <a href="to be added" target="_blank" class="external-link button is-medium is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code</span>
                    </a>
                  </span>

                  <!-- TODO: Update with your arXiv paper ID -->
                  <span class="link-block">
                    <a href="to be added" target="_blank" class="external-link button is-medium is-rounded is-dark">
                      <span class="icon">
                        <i class="ai ai-arxiv"></i>
                      </span>
                      <span>arXiv</span>
                    </a>
                  </span>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>


    <!-- Teaser video-->
    <!-- <section class="hero teaser">
      <div class="container is-max-desktop">
        <div class="hero-body">

          <div style="text-align: center; margin: 20px 0;">
            <iframe width="969" height="545" src="https://www.youtube.com/embed/f4BbxyWh6fo"
              title="UrbanIng-V2X Dataset Demonstration" frameborder="0"
              allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
              referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
          </div> -->
    <!-- TODO: Replace with your video description -->
    <!-- <h2 class="subtitle has-text-centered">
            A visual overview of UrbanIng-V2X, showcasing synchronized multi-view perception across vehicles and
            infrastructure. Each frame illustrates 3D bounding-box annotations from cameras and LiDAR sensors,
            highlighting cooperative perception and object tracking at complex urban intersections in Ingolstadt,
            Germany.
          </h2>
        </div>
      </div>
    </section> -->
    <!-- End teaser video -->

    <!-- Teaser image -->
    <section class="hero teaser">
      <div class="container is-max-desktop">
        <div class="hero-body">

          <!-- Teaser image -->
          <div style="text-align: center; margin: 20px 0;">
            <img src="static/images/teaser.jpg" alt="DrivIng dataset and digital twin visualization"
              style="max-width: 100%; height: auto;" />
          </div>

          <!-- Teaser description -->
          <h2 class="subtitle has-text-centered">
            This visualization illustrates the core features of DrivIng and its digital twin.
            The left panel shows a real-world satellite view of the track and its fully geo-referenced
            digital twin, aligned with a location marker indicating the vehicleâ€™s position.
            The right panel presents the synchronized sensor suite, including six camera views
            and a LiDAR frame. The top row displays real-world images, while the bottom row shows
            the corresponding CARLA simulation with all real-world objects precisely mapped.
            All images and the LiDAR frame include class-colored 3D bounding boxes for clear
            object distinction.
            <br /><br />
            Satellite image &copy; Esri, i-cubed, USDA, USGS, AEX, GeoEye, Getmapping,
            Aerogrid, IGN, IGP, UPR-EGP, and the GIS User Community.
          </h2>

        </div>
      </div>
    </section>
    <!-- End teaser image -->


    <!-- Paper abstract -->
    <section class="section hero is-light">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Abstract</h2>
            <div class="content has-text-justified">
              <!-- TODO: Replace with your paper abstract -->
              <p>
                Perception is a cornerstone of autonomous driving,
                enabling vehicles to understand their surroundings and make
                safe, reliable decisions. Developing robust perception algorithms
                requires large-scale, high-quality datasets that cover diverse
                driving conditions and support thorough evaluation. Existing
                datasets often lack a high-fidelity digital twin, limiting systematic
                testing, edge-case simulation, sensor modification, and sim-to-
                real evaluations. To address this gap, we present DrivIng, a
                large-scale multimodal dataset with a complete geo-referenced
                digital twin of a âˆ¼ 18 km route spanning urban, suburban, and
                highway segments. Our dataset provides continuous recordings
                from six RGB cameras, one LiDAR, and high-precision ADMA-
                based localization, captured across day, dusk, and night. All
                sequences are annotated at 10 Hz with 3D bounding boxes and
                track IDs across 12 classes, yielding âˆ¼ 1.2 million annotated
                instances. Alongside the benefits of a digital twin, DrivIng
                allows a 1-to-1 transfer of real traffic into simulation, preserving
                interactions between agents while enabling realistic and flexible
                scenario testing. We benchmark DrivIng with state-of-the-art
                perception models and publicly release the dataset, digital twin,
                HD map, and codebase to support reproducible research and
                robust validation.
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!-- End paper abstract -->

    <!-- ========================= -->
    <!-- Table I -->
    <!-- ========================= -->


    <!-- ========================= -->
    <!-- DrivIng Dataset Info -->
    <!-- ========================= -->

    <section class="section hero is-light">
      <div class="container is-max-desktop">
        <h2 class="title is-3">At a Glance</h2>

        <div class="content has-text-justified">
          <p>
            <b>DrivIng</b> is a real-world autonomous driving dataset with a fully geo-referenced <b>CARLA digital
              twin</b>,
            designed for systematic <i>sim-to-real</i> evaluation and reproducible benchmarking across matched real and
            simulated environments.
            It provides synchronized multi-sensor streams (six RGB cameras, LiDAR, and ADMA GNSS/IMU), together with 3D
            bounding-box annotations for 3D detection, tracking, and multi-modal perception.
          </p>
        </div>

        <figure class="image" style="text-align:center; margin-bottom:2rem;">
          <img src="static/images/at_a_glance_real_to_sim.jpg" alt="DrivIng real-world and CARLA digital twin overview"
            loading="lazy"
            style="max-width:100%; height:auto; border-radius:10px; box-shadow:0 2px 12px rgba(0,0,0,0.25);" />
          <figcaption class="has-text-centered" style="margin-top:0.5rem;">
            This visualization illustrates the core features of DrivIng and its digital twin. The left panel shows a
            real-world
            satellite view of the track and its fully geo-referenced digital twin, aligned with a location marker
            indicating the
            vehicleâ€™s position. The right panel presents the synchronized sensor suite, including six camera views and a
            LiDAR
            frame. The top row displays real-world images, while the bottom row shows the corresponding CARLA simulation
            with all
            real-world objects precisely mapped. All images and the LiDAR frame include class-colored 3D bounding boxes
            for clear
            object distinction. Satellite image &copy; Esri, i-cubed, USDA, USGS, AEX, GeoEye, Getmapping, Aerogrid,
            IGN, IGP,
            UPR-EGP, and the GIS User Community.
          </figcaption>
        </figure>
      </div>
    </section>

    <section class="section">
      <div class="container is-max-desktop">
        <h2 class="title is-3">Dataset Composition</h2>

        <div class="content has-text-justified">
          <p>
            DrivIng provides a synchronized and spatially calibrated multi-modal dataset paired with a geo-referenced
            CARLA
            digital twin. The dataset is organized into three continuous sequences recorded under different illumination
            conditions:
          </p>

          <ul>
            <li><b>Sequences (3):</b> Day, Dusk, and Night continuous runs.</li>
            <li><b>Coverage:</b> ~18 km route spanning urban, suburban, and highway segments (unique track length ~16
              km).</li>
            <li><b>Sensors:</b> 6 RGB cameras (360Â° coverage), 1 LiDAR, and 1 ADMA GNSS/IMU (geo-referencing and
              motion).</li>
            <li><b>Annotations:</b> 10 Hz 3D bounding boxes with track IDs in the LiDAR point cloud, aligned to the
              vehicle reference frame.</li>
            <li><b>Classes:</b> 12 object categories with class-colored 3D boxes for clear visual distinction.</li>
            <li><b>Scale:</b> ~63k annotated frames (~378k camera images, ~63k LiDAR frames) and ~1.2M labeled
              instances.</li>
            <li><b>Environments:</b> Highway, suburban streets, urban roads, and construction zones.</li>
            <li><b>Privacy:</b> Faces and license plates are anonymized in camera images.</li>
          </ul>
        </div>
      </div>
    </section>

    <section class="section hero is-light">
      <div class="container is-max-desktop">
        <h2 class="title is-3">Calibration Overview</h2>

        <div class="content has-text-justified">
          <p>
            Each sensor within DrivIng is temporally synchronized and spatially calibrated to support frame-accurate
            multi-sensor fusion and direct comparison between real-world recordings and the CARLA digital twin.
            Calibration covers <b>intrinsics</b> for each camera, <b>extrinsics</b> between cameras, LiDAR, and the ADMA
            GNSS/IMU,
            and consistent alignment to the vehicle reference frame for reliable 3D annotation projection and
            evaluation.
          </p>
        </div>

        <figure class="image" style="text-align:center; margin-bottom:2rem;">
          <img src="static/images/sensor_calibration.jpg" alt="Calibration overview for DrivIng" loading="lazy"
            style="max-width:100%; height:auto; border-radius:10px; box-shadow:0 2px 12px rgba(0,0,0,0.25);" />
          <figcaption class="has-text-centered" style="margin-top:0.5rem;">
            Temporal synchronization and spatial calibration overview for DrivIngâ€™s multi-sensor setup (six cameras,
            LiDAR, and ADMA GNSS/IMU),
            supporting consistent real-to-sim alignment and reproducible multi-modal evaluation.
          </figcaption>
        </figure>
      </div>
    </section>

    <section class="section">
      <div class="container is-max-desktop">
        <h2 class="title is-3">Coordinate System</h2>

        <div class="content has-text-justified">
          <p>
            All sensor data and 3D annotations are provided in a consistent vehicle-centric reference frame to enable
            reliable multi-sensor fusion and benchmarking. The dataset includes the necessary rigid transforms to map
            between the individual sensor frames (cameras, LiDAR, IMU) and the vehicle coordinate frame.
            The coordinate convention follows a standard automotive setup with a right-handed axis definition.
          </p>
        </div>

        <figure class="image" style="text-align:center; margin-bottom:2rem;">
          <img src="static/images/vehicle_coordinate_system.png" alt="Vehicle coordinate system and sensor placement"
            loading="lazy"
            style="max-width:100%; height:auto; border-radius:10px; box-shadow:0 2px 12px rgba(0,0,0,0.25);" />
          <figcaption class="has-text-centered" style="margin-top:0.5rem;">
            Vehicle coordinate system and sensor placement used in DrivIng. The figure illustrates the six-camera rig,
            LiDAR position,
            IMU placement, and the vehicle geometric center, together with the axis convention used for expressing 3D
            annotations and
            sensor extrinsics.
          </figcaption>
        </figure>
      </div>
    </section>




    <!-- BibTeX citation -->
    <section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
        <div class="bibtex-header">
          <h2 class="title">Citation</h2>
          <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
            <i class="fas fa-copy"></i>
            <span class="copy-text">Copy</span>
          </button>
        </div>
        <pre id="bibtex-code"><code>@misc{driving2025,
        title        = {DrivIng: A Large-Scale Multimodal Driving Dataset with Full Digital Twin Integration},
        author       = {Dominik R{\"o}{\ss}le and Xujun Xie and Adithya Mohan and
                        Venkatesh Thirugnana Sambandham and Daniel Cremers and
                        Torsten Sch{\"o}n},
        year         = {2026},
        howpublished = {Dataset and manuscript},
        note         = {Under review},
        url          = {https://example.com/driving-dataset}}
      </code></pre>
      </div>
    </section>




    <!-- ========================= -->
    <!-- Funding Logos -->
    <!-- ========================= -->
    <section class="section" style="background-color: white;">
      <div class="container has-text-centered">
        <h2 class="title is-4">Funded by:</h2>
        <div class="columns is-centered is-multiline is-vcentered" style="margin-top: 1.5rem;">

          <!-- HTA -->
          <div class="column is-narrow has-text-centered">
            <figure class="image" style="width:200px; display:flex; justify-content:center;">
              <img src="static/images/hta.png" alt="Hightech Agenda Bayern"
                style="max-height:140px; object-fit:contain;">
            </figure>
          </div>

          <!-- iExodus -->
          <div class="column is-narrow has-text-centered">
            <figure class="image" style="width:200px; display:flex; justify-content:center;">
              <img src="static/images/iexodus.png" alt="iExodus" style="max-height:140px; object-fit:contain;">
            </figure>
          </div>

          <!-- EvenFair -->
          <div class="column is-narrow has-text-centered">
            <figure class="image" style="width:200px; display:flex; justify-content:center;">
              <img src="static/images/evenfair.png" alt="Even Fair" style="max-height:140px; object-fit:contain;">
            </figure>
          </div>

          <!-- Baywiss -->
          <div class="column is-narrow has-text-centered">
            <figure class="image" style="width:200px; display:flex; justify-content:center;">
              <img src="static/images/baywiss.PNG" alt="Baywiss" style="max-height:140px; object-fit:contain;">
            </figure>
          </div>
        </div>
      </div>
    </section>



    <section class="section" style="background-color: white;">
      <div class="container has-text-centered">
        <h2 class="title is-4">Data Privacy:</h2>
        <div class="columns is-centered is-multiline is-vcentered" style="margin-top: 1.5rem;">

          <div class="has-text-centered" style="margin-top:1.5rem;">
            <a href="https://www.thi.de/forschung/aimotion/datarecording/" target="_blank" rel="noopener noreferrer"
              style="color:#1a73e8; text-decoration:none; font-weight:500;">
              ðŸ”’ Data Privacy Policy (THI)
            </a>
          </div>


          <footer class="footer">
            <div class="container">
              <div class="columns is-centered">
                <div class="column is-8">
                  <div class="content">

                    <p>
                      This page was built using the <a
                        href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic
                        Project Page Template</a> which was adopted from theÂ <a href="https://nerfies.github.io"
                        target="_blank">Nerfies</a>Â project page.
                      You are free to borrow the source code of this website, we just ask that you link back to
                      this
                      page in
                      the footer. <br> This website is licensed under a <a rel="license"
                        href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                        Commons Attribution-ShareAlike 4.0 International License</a>.
                    </p>

                  </div>
                </div>
              </div>
            </div>
          </footer>

          <!-- Statcounter tracking code -->

          <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

          <!-- End of Statcounter Code -->

</body>

</html>